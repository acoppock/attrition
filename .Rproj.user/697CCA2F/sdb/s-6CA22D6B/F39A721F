{
    "collab_server" : "",
    "contents" : "## Levendusky Double Sampling\nrm(list=ls())\nsetwd(\"~/Documents/Dropbox/Columbia/Collaboration/Work for Don/Double sampling/Levendusky_Replications/\")\nsource(\"programs/estimator_ds.r\")\nsource(\"../sampling-package-12-2-14.R\")\nsource(\"programs/two-sampling-trimming-bounds.R\")\nload(\"data/levendusky_mturk.rdata\")\nload(\"data/levendusky_gfk.rdata\")\n\nlibrary(ggplot2)\nlibrary(car)\nlibrary(xtable)\nlibrary(dplyr)\n\n# Mechanical Turk ---------------------------------------------------------\n\n# Create Ns Table\n\nmturk_table_1_2 <- \nlevendusky_mturk %>%\n  filter(Z_Levendusky != \"placebo\") %>%\n  group_by(Z_lev) %>%\n  summarize(wave_1_total = n(),\n            wave_2_responded = sum(R1),\n            wave_2_didntrespond = sum(1-R1),\n            wave_2_reattempted = sum(Attempt),\n            wave_2_respondedtoattempt = sum(R2))\n\nmturk_table_3 <- \n  levendusky_mturk %>%\n  filter(Z_Levendusky != \"placebo\") %>%\n  summarize(Z_lev = \"Total\",\n            wave_1_total = n(),\n            wave_2_responded = sum(R1),\n            wave_2_didntrespond = sum(1-R1),\n            wave_2_reattempted = sum(Attempt),\n            wave_2_respondedtoattempt = sum(R2))\n\nmturk_table <- rbind(mturk_table_1_2, mturk_table_3)\n\nprint.xtable(xtable(mturk_table, digits = 0), \n             include.rownames = FALSE, include.colnames = FALSE, \n             hline.after = c(2), only.contents = TRUE,file = \"../PA/mturk_responses.tex\")\n\n# Bounds\n\ncis1 <- estimator.ev(Y=\"L_dif_w2\", Z = \"Z1\", R1 = \"R1\",\n                     minY = 0, maxY = 6, alpha = 0.05, \n                     data = subset(levendusky_mturk, !is.na(Z1)))\n\ncis2 <- estimator.ds(Y=\"L_dif_w2\", Z = \"Z1\", R1 = \"R1\", Attempt = \"Attempt\", \n                     R2 = \"R2\", minY = 0, maxY = 6, alpha = 0.05, \n                     data = subset(levendusky_mturk, !is.na(Z1)))\n\ncis3 <- estimator.ds(Y=\"L_dif_w2\", Z = \"Z1\", R1 = \"R1\", Attempt = \"Attempt\", \n                     R2 = \"R2\", minY = 0, maxY = 6, alpha = 0.05, strata=\"pid_3_recoded\",\n                     data = subset(levendusky_mturk, !is.na(Z1)))\n\nmturk_results <- cbind(cis1, cis2, cis3)\n\nwidths <- mturk_results[2,] - mturk_results[1,] \n(widths[1] - widths[3] )/ widths[1]\n\nrow.names(mturk_results) <- c(\"95% CI Lower Bound\",\"95% CI Upper Bound\", \n                              \"Worst-Case Bound: Low Estimate\", \"Worst-Case Bound: High Estimate\",\n                              \"Variance of Low Estimate\", \"Variance of High Estimate\")\n\nprint.xtable(xtable(mturk_results, digits=4), only.contents = TRUE, \n             include.colnames = FALSE, hline.after = c(),file = \"../PA/mturk_results.tex\")\n\n# Means\n\nmturk_means_table <- \n  levendusky_mturk %>%\n  filter(Z_Levendusky != \"placebo\") %>%\n  group_by(Z_lev) %>%\n  summarize(IR_mean = mean(L_dif_w2[R1==1]),\n            IR_sd = sd(L_dif_w2[R1==1]),\n            IR_N = length(L_dif_w2[R1==1]),\n            DS_mean = mean(L_dif_w2[R2==1]),\n            DS_sd = sd(L_dif_w2[R2==1]),\n            DS_N = length(L_dif_w2[R2==1]))\n\n\nprint.xtable(xtable(mturk_means_table, digits=3), only.contents = TRUE, include.rownames = FALSE,\n             include.colnames = FALSE, hline.after = c(),file = \"../PA/mturk_means.tex\")\n\n\nfit <- lm(L_dif_w2 ~ Z_Levendusky, subset(levendusky_mturk, Z_Levendusky != \"placebo\"))\nfit_r <- commarobust(fit)\n\n\n\n\n# Trimming\n\n# Include the n observations successfully sampled in the first round.\n# Denote Fail = 0, and Weight = 1 for all observations.\n\n# Add the observations that we attempted to sample in the second round.\n# For all units that respond, set Fail = 0. If we did not get a\n# response, record their Out as -99 and Fail as 1. \n# For units in the treatment condition, let \n# Weight = (Number of Treated Units that did not Respond in First Round)/\n#          (Number of Treated Units Attempted to Double Sample). \n\n# For units in the control condition, let \n# Weight = (Number of Control Units that did not Respond in First Round)/\n# (Number of Control Units Attempted to Double Sample).\n\nlevendusky_mturk_subset <- filter(levendusky_mturk, Z_Levendusky != \"placebo\")\n\nlevendusky_mturk_subset <-  within(levendusky_mturk_subset, {\n\n  Out <- L_dif_w2\n  Out[is.na(L_dif_w2)] <- -99\n  \n  Treat <- as.numeric(Z_Levendusky == \"polarized\")\n  Fail <- as.numeric(is.na(L_dif_w2))\n  \n  Weight <- rep(NA, nrow(levendusky_mturk_subset))\n  \n  Weight[R1==1] <- 1\n  Weight[Attempt==1 & Treat ==1] <- sum(Treat == 1 & R1 == 0)/sum(Treat == 1 & Attempt == 1)\n  Weight[Attempt==1 & Treat ==0] <- sum(Treat == 0 & R1 == 0)/sum(Treat == 0 & Attempt == 1)\n})\n\nwith(levendusky_mturk_subset, table(Out, exclude = NULL))\nwith(levendusky_mturk_subset, table(Treat, exclude = NULL))\nwith(levendusky_mturk_subset, table(Fail, exclude = NULL))\nwith(levendusky_mturk_subset, table(Weight, exclude = NULL))\n\nfilter(levendusky_mturk_subset, R1 == 1 | Attempt == 1) %>% nrow\n\nmturk_trimming <- with(filter(levendusky_mturk_subset, R1 == 1 | Attempt == 1),\n                       returnbounds(Out = Out, Treat = Treat, Fail = Fail, Weight = Weight))\nmturk_trimming\n\nmturk_trimming$Out1L - mturk_trimming$Out0U\nmturk_trimming$Out1U - mturk_trimming$Out0L\n\nmturk_gg <- data.frame(uis = c(mturk_results[2,1:2], fit_r[2,1] + 1.96*fit_r[2,2], NA),\n                       lis = c(mturk_results[1,1:2], fit_r[2,1] - 1.96*fit_r[2,2], NA),\n                       point_estimate = c(NA, NA, fit_r[2,1], NA),\n                       high_est = c(mturk_results[4,1:2], NA, mturk_trimming$Out1U - mturk_trimming$Out0L),\n                       low_est = c(mturk_results[3,1:2], NA, mturk_trimming$Out1L - mturk_trimming$Out0U),\n                       estimator = c(\"Extreme Value Bounds\", \"EVB + Double Sampling\", \"Naive\", \"Trimming\"),\n                       Study = \"Polarization: Mturk\")\n\n\n\n# GfK ---------------------------------------------------------------------\n\n\n# Create Ns Table\ngfk_table_1_2 <- \n  levendusky_gfk %>%\n  filter(Z_Levendusky != \"placebo\") %>%\n  group_by(Z_lev) %>%\n  summarize(wave_1_total = n(),\n            wave_2_responded = sum(R1),\n            wave_2_didntrespond = sum(1-R1),\n            wave_2_reattempted = sum(Attempt),\n            wave_2_respondedtoattempt = sum(R2))\n\ngfk_table_3 <- \n  levendusky_gfk %>%\n  filter(Z_Levendusky != \"placebo\") %>%\n  summarize(Z_lev = \"Total\",\n            wave_1_total = n(),\n            wave_2_responded = sum(R1),\n            wave_2_didntrespond = sum(1-R1),\n            wave_2_reattempted = sum(Attempt),\n            wave_2_respondedtoattempt = sum(R2))\n\ngfk_table <- rbind(gfk_table_1_2, gfk_table_3)\n\nprint.xtable(xtable(gfk_table, digits = 0), \n             include.rownames = FALSE, include.colnames = FALSE, \n             hline.after = c(2), only.contents = TRUE,file = \"../PA/gfk_responses.tex\")\n\n# Bounds\n\ncis1 <- estimator.ev(Y=\"L_dif_w2\", Z = \"Z1\", R1 = \"R1\",\n                     minY = 0, maxY = 6, alpha = 0.05, \n                     data = subset(levendusky_gfk, !is.na(Z1)))\n\ncis2 <- estimator.ds(Y=\"L_dif_w2\", Z = \"Z1\", R1 = \"R1\", Attempt = \"Attempt\", \n                     R2 = \"R2\", minY = 0, maxY = 6, alpha = 0.05, \n                     data = subset(levendusky_gfk, !is.na(Z1)))\n\ncis3 <- estimator.ds(Y=\"L_dif_w2\", Z = \"Z1\", R1 = \"R1\", Attempt = \"Attempt\", \n                     R2 = \"R2\", minY = 0, maxY = 6, alpha = 0.05, strata=\"pid_3_recoded\",\n                     data = subset(levendusky_gfk, !is.na(Z1)))\n\ngfk_results <- cbind(cis1, cis2, cis3)\n\nwidths <- gfk_results[2,] - gfk_results[1,] \n(widths[1] - widths[3] )/ widths[1]\n\nrow.names(gfk_results) <- c(\"95% CI Lower Bound\",\"95% CI Upper Bound\", \n                              \"Worst-Case Bound: Low Estimate\", \"Worst-Case Bound: High Estimate\",\n                              \"Variance of Low Estimate\", \"Variance of High Estimate\")\n\nprint.xtable(xtable(gfk_results, digits=4), only.contents = TRUE, \n             include.colnames = FALSE, hline.after = c(),file = \"../PA/gfk_results.tex\")\n\n# Means\n\ngfk_means_table <- \n  levendusky_gfk %>%\n  filter(Z_Levendusky != \"placebo\") %>%\n  group_by(Z_lev) %>%\n  summarize(IR_mean = mean(L_dif_w2[R1==1]),\n            IR_sd = sd(L_dif_w2[R1==1]),\n            IR_N = length(L_dif_w2[R1==1]),\n            DS_mean = mean(L_dif_w2[R2==1]),\n            DS_sd = sd(L_dif_w2[R2==1]),\n            DS_N = length(L_dif_w2[R2==1]))\n\n\nprint.xtable(xtable(gfk_means_table, digits=3), only.contents = TRUE, include.rownames = FALSE,\n             include.colnames = FALSE, hline.after = c(),file = \"../PA/gfk_means.tex\")\n\n\nfit <- lm(L_dif_w2 ~ Z_Levendusky, subset(levendusky_gfk, Z_Levendusky != \"placebo\"))\nfit_r <- commarobust(fit)\n\n\n\n\n# Trimming\n\n# Include the n observations successfully sampled in the first round.\n# Denote Fail = 0, and Weight = 1 for all observations.\n\n# Add the observations that we attempted to sample in the second round.\n# For all units that respond, set Fail = 0. If we did not get a\n# response, record their Out as -99 and Fail as 1. \n# For units in the treatment condition, let \n# Weight = (Number of Treated Units that did not Respond in First Round)/\n#          (Number of Treated Units Attempted to Double Sample). \n\n# For units in the control condition, let \n# Weight = (Number of Control Units that did not Respond in First Round)/\n# (Number of Control Units Attempted to Double Sample).\n\nlevendusky_gfk_subset <- filter(levendusky_gfk, Z_Levendusky != \"placebo\")\n\nlevendusky_gfk_subset <-  within(levendusky_gfk_subset, {\n  \n  Out <- L_dif_w2\n  Out[is.na(L_dif_w2)] <- -99\n  \n  Treat <- as.numeric(Z_Levendusky == \"polarized\")\n  Fail <- as.numeric(is.na(L_dif_w2))\n  \n  Weight <- rep(NA, nrow(levendusky_gfk_subset))\n  \n  Weight[R1==1] <- 1\n  Weight[Attempt==1 & Treat ==1] <- sum(Treat == 1 & R1 == 0)/sum(Treat == 1 & Attempt == 1)\n  Weight[Attempt==1 & Treat ==0] <- sum(Treat == 0 & R1 == 0)/sum(Treat == 0 & Attempt == 1)\n})\n\nwith(levendusky_gfk_subset, table(Out, exclude = NULL))\nwith(levendusky_gfk_subset, table(Treat, exclude = NULL))\nwith(levendusky_gfk_subset, table(Fail, exclude = NULL))\nwith(levendusky_gfk_subset, table(Weight, exclude = NULL))\n\ngfk_trimming <- with(filter(levendusky_gfk_subset, R1 == 1 | Attempt == 1),\n                     returnbounds(Out = Out, Treat = Treat, Fail = Fail, Weight = Weight))\ngfk_trimming\n\n\n\ngfk_gg <- data.frame(uis = c(gfk_results[2,1:2], fit_r[2,1] + 1.96*fit_r[2,2], NA),\n                       lis = c(gfk_results[1,1:2], fit_r[2,1] - 1.96*fit_r[2,2], NA),\n                       point_estimate = c(NA, NA, fit_r[2,1], NA),\n                       high_est = c(gfk_results[4,1:2], NA, gfk_trimming$Out1U - gfk_trimming$Out0L),\n                       low_est = c(gfk_results[3,1:2], NA, gfk_trimming$Out1L - gfk_trimming$Out0U),\n                       estimator = c(\"Extreme Value Bounds\", \"EVB + Double Sampling\", \"Naive\", \"Trimming\"),\n                       Study = \"Polarization: gfk\")\n\n\ndf_gg <- \nbind_rows(mturk_gg, gfk_gg) %>%\n  mutate(estimator = factor(estimator, levels = c(\"Extreme Value Bounds\", \"EVB + Double Sampling\", \"Naive\", \"Trimming\")))\n\n\nwrite.csv(df_gg, file = \"estimators_table.csv\", row.names = FALSE)\n\n\npro_con_colors <- c(\"#205C8A\", \"#C67800\")\ncolorfunction <- colorRampPalette(pro_con_colors)\npred_cols <- colorfunction(4)\nlibrary(grid)\n\ng <- \n\n  ggplot(aes(x= estimator, color=estimator)) +\n  geom_linerange(aes(ymax=uis, ymin=lis), size=1.5) +\n  geom_point(aes(y=high_est), size=3) +\n  geom_point(aes(y=low_est), size=3) +\n  geom_point(aes(y=point_estimate), size=3) +\n  geom_hline(yintercept=0, linetype=\"dashed\") +\n  scale_color_manual(values=pred_cols) +\n  facet_wrap(~Study) +\n  theme_bw() +\n  ylab(\"Time 2 Average Treatment Effect\") + \n  theme(legend.position=\"bottom\", axis.title.x = element_blank(),\n        legend.position=\"none\", \n        legend.title = element_blank(),\n        legend.direction = \"vertical\",\n        legend.key.width = unit(10, \"lines\"),\n        strip.background = element_blank(),\n        panel.background = element_blank(),\n        panel.grid = element_blank(),\n        panel.border = element_rect(size=1.5, colour= \"#222222\"),\n        axis.ticks = element_line(colour= \"#222222\"),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        plot.background = element_blank())\n\ng\n\n\nggsave(filename = \"estimators_plot.pdf\", plot = g, height = 7, width=9)\n\n\n\n",
    "created" : 1452196663584.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "156918099",
    "id" : "F39A721F",
    "lastKnownWriteTime" : 1452026199,
    "last_content_update" : 1452026199,
    "path" : "~/Documents/Dropbox/Columbia/Collaboration/Work for Don/Double sampling/Levendusky_Replications/programs/levendusky_analysis_ds.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}